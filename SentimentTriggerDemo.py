import torch
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
from transformers import AutoModelForCausalLM

# -----------------------
# Step 1. åˆ¤åˆ«å¼æ¨¡å‹ (Erlangshen)
# -----------------------
sentiment_model_name = "IDEA-CCNL/Erlangshen-Roberta-110M-Sentiment"  # è½»é‡ç‰ˆ
tokenizer = AutoTokenizer.from_pretrained(sentiment_model_name)
model = AutoModelForSequenceClassification.from_pretrained(sentiment_model_name)

device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
sentiment_analyzer = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer, device=-1)

# -----------------------
# Step 2. ç”Ÿæˆå¼å¤§æ¨¡å‹ (Qwen)
# -----------------------
gen_model_name = "Qwen/Qwen1.5-1.8B-Chat"  # å»ºè®®å°æ¨¡å‹è·‘ Demoï¼Œ7B ä¼šçˆ†å†…å­˜
gen_tokenizer = AutoTokenizer.from_pretrained(gen_model_name)
gen_model = AutoModelForCausalLM.from_pretrained(gen_model_name, device_map="auto")

def explain_trigger(sentence, candidate_labels):
    """ç”¨ç”Ÿæˆæ¨¡å‹è§£é‡Šè§¦å‘åŸå› """
    prompt = f"""
è¯·åˆ†æä¸‹é¢å¥å­å¯èƒ½å¼•å‘å¯¹è¯å†²çªæˆ–æƒ…ç»ªå‡çº§çš„åŸå› ã€‚å€™é€‰æ ‡ç­¾å¦‚ä¸‹ï¼š
{candidate_labels}

å¥å­ï¼š{sentence}

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š
å¯èƒ½çš„è§¦å‘åŸå› ï¼š
- æ ‡ç­¾ (ç½®ä¿¡åº¦æˆ–åˆç†æ€§è¯´æ˜)
"""
    inputs = gen_tokenizer(prompt, return_tensors="pt").to(gen_model.device)
    outputs = gen_model.generate(**inputs, max_new_tokens=256)
    return gen_tokenizer.decode(outputs[0], skip_special_tokens=True)

# -----------------------
# Step 3. Demo æµç¨‹
# -----------------------
conversation = [
    "æˆ‘è§‰å¾—è‡ªå·±å¥½å¯æ€œï¼Œå¤©å¤©ä¸€ä¸ªäººåŠ ç­ã€‚",
    "ä½ ä»–å¦ˆçš„é—­å˜´ï¼"
]

# 1) åˆ¤åˆ«å¼æ¨¡å‹é€å¥æƒ…ç»ªåˆ†ç±»
results = sentiment_analyzer(conversation)

print("ğŸŸ¡ æƒ…ç»ªæ£€æµ‹ç»“æœï¼š")
for i, (sent, res) in enumerate(zip(conversation, results)):
    print(f"- ç¬¬{i+1}å¥: {sent} â†’ {res['label']} ({res['score']:.2f})")

# 2) è§¦å‘ç‚¹æ£€æµ‹ï¼ˆç®€å•ç‰ˆï¼šçœ‹æœ€åä¸€å¥ vs å‰é¢å¥å­çš„å·®å¼‚ï¼‰
last_res = results[-1]
trigger_idx, max_shift = -1, 0
for i in range(len(results)-1):
    shift = last_res['score'] - results[i]['score'] if results[i]['label'] != "NEGATIVE" else 0
    if shift > max_shift:
        max_shift, trigger_idx = shift, i

# 3) å¦‚æœæ‰¾åˆ°è§¦å‘ç‚¹ â†’ è°ƒç”¨ç”Ÿæˆå¼å¤§æ¨¡å‹è§£é‡Š
if trigger_idx >= 0:
    trigger_sentence = conversation[trigger_idx]
    print(f"\nâš ï¸ è§¦å‘ç‚¹å¯èƒ½æ˜¯ç¬¬ {trigger_idx+1} å¥: \"{trigger_sentence}\"")

    candidate_labels = [
    "è´£å¤‡æˆ–æŒ‡è´£",
    "è¯­æ°”ä¸è€çƒ¦",
    "ç¼ºä¹å…³å¿ƒæˆ–æ”¯æŒ",
    "è¡¨è¾¾æ— å¥ˆå’ŒæŠ±æ€¨",
    "è¡¨è¾¾æ¨¡ç³Šï¼Œå®¹æ˜“è¢«è¯¯è§£",
    "å¸¦æœ‰æ‰¹è¯„æ„å‘³"
  ]
    explanation = explain_trigger(trigger_sentence, candidate_labels)
    print("\nğŸ” å¯èƒ½çš„è§¦å‘åŸå› ï¼š")
    print(explanation)
else:
    print("\nâš ï¸ æœªèƒ½æ‰¾åˆ°æ˜æ˜¾è§¦å‘ç‚¹ã€‚")