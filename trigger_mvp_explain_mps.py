# V1.0.0
import torch
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    pipeline
)
import time
from datetime import datetime

# =========================
# è®¾å¤‡é€‰æ‹©
# =========================
# è‡ªåŠ¨æ£€æµ‹æ˜¯å¦æ”¯æŒ Apple Silicon GPU (MPS)
if torch.backends.mps.is_available():
    device = torch.device("mps")
    device_id = 0  # pipeline é‡Œç”¨ 0 è¡¨ç¤ºå¯ç”¨ GPU
    print("Using Apple Silicon GPU (MPS)")
elif torch.cuda.is_available():
    device = torch.device("cuda")
    device_id = 0
    print("Using NVIDIA CUDA GPU")
else:
    device = torch.device("cpu")
    device_id = -1
    print("Using CPU")

# =========================
# Sentiment Analysis (æƒ…ç»ªåˆ†æ)
# =========================
sentiment_model_name = "distilbert-base-uncased-finetuned-sst-2-english"
sentiment_tokenizer = AutoTokenizer.from_pretrained(sentiment_model_name)
sentiment_model = AutoModelForSequenceClassification.from_pretrained(sentiment_model_name)
sentiment_model.to(device)

# sentiment analysis pipeline
sentiment_analyzer = pipeline(
    "sentiment-analysis",
    model=sentiment_model,
    tokenizer=sentiment_tokenizer,
    device=device_id
)

# =========================
# Zero-shot Classification (è§£é‡Šå±‚)
# =========================
explain_model_name = "facebook/bart-large-mnli"
explain_tokenizer = AutoTokenizer.from_pretrained(explain_model_name)
explain_model = AutoModelForSequenceClassification.from_pretrained(explain_model_name)
explain_model.to(device)

# zero-shot classification pipeline
explain_analyzer = pipeline(
    "zero-shot-classification",
    model=explain_model,
    tokenizer=explain_tokenizer,
    device=device_id
)

# =========================
# Trigger Detection å‡½æ•°
# =========================
def detect_trigger(conversation):
    results = [sentiment_analyzer(utt)[0] for utt in conversation]

    print("\næƒ…ç»ªåˆ†æç»“æœï¼š")
    for i, (utt, res) in enumerate(zip(conversation, results)):
        print(f"{i+1}. {utt} --> {res}")

    last_res = results[-1]
    if last_res['label'] != "NEGATIVE":
        print("\nâŒ æœ€åä¸€å¥ä¸æ˜¯è´Ÿé¢æƒ…ç»ªï¼Œä¸éœ€è¦è§¦å‘æ£€æµ‹ã€‚")
        return None, None

    trigger_idx = -1
    max_shift = 0
    for i in range(len(results)-1):
        shift = last_res['score'] - results[i]['score'] if results[i]['label'] != "NEGATIVE" else 0
        if shift > max_shift:
            max_shift = shift
            trigger_idx = i

    if trigger_idx >= 0:
        trigger_sentence = conversation[trigger_idx]
        print(f"\nâš ï¸ è§¦å‘ç‚¹å¯èƒ½æ˜¯ç¬¬ {trigger_idx+1} å¥: \"{trigger_sentence}\"")

        # å€™é€‰è§£é‡Šæ ‡ç­¾
        candidate_labels = [
            "è´£å¤‡æˆ–æŒ‡è´£",
            "è¯­æ°”ä¸è€çƒ¦",
            "ç¼ºä¹å…³å¿ƒæˆ–æ”¯æŒ",
            "è¡¨è¾¾æ¨¡ç³Šï¼Œå®¹æ˜“è¢«è¯¯è§£",
            "å¸¦æœ‰æ‰¹è¯„æ„å‘³"
        ]
        explanation = explain_analyzer(trigger_sentence, candidate_labels)
        print("\nğŸ” å¯èƒ½çš„è§¦å‘åŸå› ï¼š")
        for lbl, score in zip(explanation["labels"], explanation["scores"]):
            print(f"- {lbl} ({score:.2f})")

        return trigger_sentence, explanation
    else:
        print("\nâš ï¸ æœªèƒ½æ‰¾åˆ°æ˜æ˜¾è§¦å‘ç‚¹ã€‚")
        return None, None


# =========================
# æµ‹è¯•è¿è¡Œ
# =========================
t1 = time.time()
if __name__ == "__main__":
    convo = [
        "Hey Cathy, could you help me with my tax refund?",
        "I already told you, that's not my problem.",
        "Why are you being so rude?"
    ]
    detect_trigger(convo)
t2 = time.time()
diff_seconds = round(t2 - t1, 2)
print("\næ€»è€—æ—¶ï¼š", diff_seconds, "ç§’")
